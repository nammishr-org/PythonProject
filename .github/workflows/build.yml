name: Backup Audit Tables to S3

on:
  push:
    branches:
      - '**'
    tags-ignore:
      - '**'
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

jobs:
  backup:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:13
        ports:
          - 5432:5432
        env:
          POSTGRES_DB: testdatabase
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpassword

    env:
      DB_HOST: localhost
      DB_PORT: 5432
      DB_NAME: testdatabase
      DB_USER: testuser
      DB_PASSWORD: testpassword
      S3_BUCKET_NAME: audit-table-archives
      S3_PREFIX: audit_zipped_files
      S3_REGION: us-east-1

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials (OIDC)
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::977016738307:role/GithubActionsS3Role
        aws-region: us-east-1

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12.7'

    - name: Install dependencies
      run: pip install boto3 psycopg2-binary

    - name: Wait for Postgres to be ready
      run: |
          echo "Waiting for PostgreSQL to be ready..."
          sleep 15  # Let DB start before running script

    - name: Create dummy audit table and data
      run: |
              PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -U $DB_USER -d $DB_NAME -c \
              "CREATE table gha_request_timestamps(
              id SERIAL PRIMARY KEY,
              repo_name VARCHAR(255),
              request_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
              processed BOOLEAN DEFAULT false
              );"
              
              PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -U $DB_USER -d $DB_NAME -c \
              "INSERT INTO public.gha_request_timestamps
              (id, repo_name, "timestamp", processed)
              VALUES(37, 'TT-1-service', '2025-05-15 11:36:59.021', false);"
    

    - name: Run audit backup script
      run: python AuditMyBackup.py


    - name: Verify backup file was uploaded to S3
      run: |
              echo "Listing contents of S3 bucket $S3_BUCKET..."
              aws s3 ls s3://S3_BUCKET_NAME/ --region $AWS_REGION